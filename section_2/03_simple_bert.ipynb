{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/bert_nlp/blob/main/section_2/03_simple_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv454lBK1YCc"
      },
      "source": [
        "# シンプルなBERTの実装\n",
        "訓練済みのモデルを使用し、文章の一部の予測、及び2つの文章が連続しているかどうかの判定を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Ozfz3NhltP"
      },
      "source": [
        "## ライブラリのインストール\n",
        "PyTorch-Transformers、および必要なライブラリのインストールを行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y_mDYVlb-sqi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: folium==0.2.1 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (0.2.1)\n",
            "Requirement already satisfied: Jinja2 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from folium==0.2.1) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (1.25.11)\n",
            "Requirement already satisfied: pytorch-transformers==1.2.0 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (1.2.0)\n",
            "Requirement already satisfied: sacremoses in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (0.0.46)\n",
            "Requirement already satisfied: tqdm in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (2.26.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (1.9.0)\n",
            "Requirement already satisfied: boto3 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (1.18.60)\n",
            "Requirement already satisfied: sentencepiece in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (0.1.96)\n",
            "Requirement already satisfied: regex in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (2021.10.8)\n",
            "Requirement already satisfied: numpy in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from pytorch-transformers==1.2.0) (1.21.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from torch>=1.0.0->pytorch-transformers==1.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from boto3->pytorch-transformers==1.2.0) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from boto3->pytorch-transformers==1.2.0) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.60 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from boto3->pytorch-transformers==1.2.0) (1.21.60)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from requests->pytorch-transformers==1.2.0) (1.25.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from requests->pytorch-transformers==1.2.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from requests->pytorch-transformers==1.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from requests->pytorch-transformers==1.2.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from sacremoses->pytorch-transformers==1.2.0) (8.0.3)\n",
            "Requirement already satisfied: six in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from sacremoses->pytorch-transformers==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: joblib in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from sacremoses->pytorch-transformers==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/zinc/miniforge3/envs/bert_nlp/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.60->boto3->pytorch-transformers==1.2.0) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install folium==0.2.1\n",
        "!pip install urllib3==1.25.11\n",
        "!pip install pytorch-transformers==1.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5gVyYF2vjL"
      },
      "source": [
        "## 文章の一部の予測\n",
        "文章における一部の単語をMASKし、それをBERTのモデルを使って予測します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G6oFZnS21Mqs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'i', 'played', 'baseball', 'with', 'my', 'friends', 'at', 'school', 'yesterday', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pytorch_transformers import BertForMaskedLM\n",
        "from pytorch_transformers import BertTokenizer\n",
        "#今回は設定しないのでconfigは不要\n",
        "\n",
        "text = \"[CLS] I played baseball with my friends at school yesterday [SEP]\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "words = tokenizer.tokenize(text)#textsをwordsに変換\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Y32Tl55dSl"
      },
      "source": [
        "文章の一部をMASKします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0_H50V7b5RM0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'i', 'played', '[MASK]', 'with', 'my', 'friends', 'at', 'school', 'yesterday', '[SEP]']\n"
          ]
        }
      ],
      "source": [
        "msk_idx = 3\n",
        "words[msk_idx] = \"[MASK]\"  # msk_idxの単語(baseball)を[MASK]に置き換える\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBXgAn9s528_"
      },
      "source": [
        "単語を対応するインデックスに変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "zm4qbMPW56-w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "tensor([[ 101, 1045, 2209,  103, 2007, 2026, 2814, 2012, 2082, 7483,  102]])\n"
          ]
        }
      ],
      "source": [
        "word_ids = tokenizer.convert_tokens_to_ids(words)  # 単語をインデックスに変換\n",
        "print(type(word_ids))\n",
        "word_tensor = torch.tensor([word_ids])  # テンソルに変換\n",
        "print(word_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y76O88877cB_"
      },
      "source": [
        "BERTのモデルを使って予測を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "M2NWREc77gQC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: (tensor([[[ -6.6873,  -6.6405,  -6.6409,  ...,  -6.0201,  -5.8183,  -3.9777],\n",
            "         [ -9.5150,  -9.3415,  -9.3818,  ...,  -8.4236,  -8.4428,  -5.3152],\n",
            "         [-10.0567, -10.1768, -10.2753,  ...,  -8.5044,  -8.6216,  -5.3011],\n",
            "         ...,\n",
            "         [-13.6662, -14.2769, -13.8572,  ..., -12.8681, -11.8016, -11.4663],\n",
            "         [ -9.2015,  -8.9383,  -9.3056,  ...,  -7.7869,  -9.2608,  -3.0500],\n",
            "         [-13.1242, -12.9604, -12.7900,  ...,  -9.9769, -10.1773, -10.8939]]],\n",
            "       grad_fn=<AddBackward0>),)\n",
            "y[0]: tensor([[[ -6.6873,  -6.6405,  -6.6409,  ...,  -6.0201,  -5.8183,  -3.9777],\n",
            "         [ -9.5150,  -9.3415,  -9.3818,  ...,  -8.4236,  -8.4428,  -5.3152],\n",
            "         [-10.0567, -10.1768, -10.2753,  ...,  -8.5044,  -8.6216,  -5.3011],\n",
            "         ...,\n",
            "         [-13.6662, -14.2769, -13.8572,  ..., -12.8681, -11.8016, -11.4663],\n",
            "         [ -9.2015,  -8.9383,  -9.3056,  ...,  -7.7869,  -9.2608,  -3.0500],\n",
            "         [-13.1242, -12.9604, -12.7900,  ...,  -9.9769, -10.1773, -10.8939]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "y[0].size(): torch.Size([1, 11, 30522])\n",
            "_: tensor([10.5885, 10.5762,  9.9564,  9.8097,  9.1332], grad_fn=<TopkBackward>)\n",
            "max_ids: tensor([3455, 2374, 4715, 3598, 5093])\n",
            "['basketball', 'football', 'soccer', 'baseball', 'tennis']\n"
          ]
        }
      ],
      "source": [
        "msk_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "# msk_model.cuda()  # GPU対応\n",
        "msk_model.eval()#評価モード\n",
        "\n",
        "# x = word_tensor.cuda()  # GPU対応\n",
        "x = word_tensor  # xとしてid化したwordsを与える。GPUなし\n",
        "y = msk_model(x)  # 順伝搬を1回行って予測\n",
        "print('y:',y)\n",
        "result = y[0]#tensorの要素はバッチ毎なので、0バッチ目をスライス\n",
        "print('y[0]:',result)\n",
        "print('y[0].size():',result.size())  # 結果の形状:1,11,30522 1:バッチサイズ 11:学習した文章のサイズ 30522:全トークン数\n",
        "\n",
        "_, max_ids = torch.topk(result[0][msk_idx], k=5)  # 最も大きい5つの値と、その大きい値のインデックス\n",
        "print('_:',_)\n",
        "print('max_ids:',max_ids)\n",
        "result_words = tokenizer.convert_ids_to_tokens(max_ids.tolist())  # インデックスを単語に変換\n",
        "print(result_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "result[0][3]: tensor([-5.3318, -5.5466, -5.5536,  ..., -5.1736, -5.8427, -4.8701],\n",
            "       grad_fn=<SelectBackward>)\n",
            "result[0][3].argmax(): tensor(3455)\n",
            "idからwordに変換 basketball\n"
          ]
        }
      ],
      "source": [
        "print('result[0][3]:',result[0][3])  # 単語をインデックスに変換\n",
        "print('result[0][3].argmax():',result[0][3].argmax())\n",
        "print('idからwordに変換',tokenizer.convert_ids_to_tokens(result[0][3].argmax().item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Su6QTCAAgFS"
      },
      "source": [
        "## 文章が連続しているかどうかの判定\n",
        "BERTのモデルを使って、2つの文章が連続しているかどうかの判定を行います。  \n",
        "以下の関数`show_continuity`では、2つの文章の連続性を判定し、表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FC0nihWMAtgG"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import BertForNextSentencePrediction\n",
        "\n",
        "def show_continuity(text, seg_ids):\n",
        "    words = tokenizer.tokenize(text)#単語分割\n",
        "    word_ids = tokenizer.convert_tokens_to_ids(words)  # 単語をインデックスに変換\n",
        "    word_tensor = torch.tensor([word_ids])  # テンソルに変換\n",
        "\n",
        "    seg_tensor = torch.tensor([seg_ids])\n",
        "\n",
        "    nsp_model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
        "    # nsp_model.cuda()  # GPU対応\n",
        "    nsp_model.eval()#評価モード\n",
        "\n",
        "    # x = word_tensor.cuda()  # GPU対応\n",
        "    x = word_tensor  # GPUなし\n",
        "    # s = seg_tensor.cuda()  # GPU対応\n",
        "    s = seg_tensor  # GPUなし\n",
        "\n",
        "    y = nsp_model(x, s)  # 予測\n",
        "    result = torch.softmax(y[0], dim=1)#resultをsoftmaxに入れ、確率にする\n",
        "    print(result)\n",
        "    print(str(result[0][0].item()*100) + \"%の確率で連続しています。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWogb8nFIQMg"
      },
      "source": [
        "`show_continuity`関数に、自然につながる2つの文章を与えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "OaUmof1yF_rD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'what', 'is', 'baseball', '?', '[SEP]', 'it', 'is', 'a', 'game', 'of', 'hitting', 'the', 'ball', 'with', 'the', 'bat', '[SEP]']\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([[1.0000e+00, 4.5869e-06]], grad_fn=<SoftmaxBackward>)\n",
            "99.9995470046997%の確率で連続しています。\n"
          ]
        }
      ],
      "source": [
        "text = \"[CLS] What is baseball ? [SEP] It is a game of hitting the ball with the bat [SEP]\"\n",
        "print(tokenizer.tokenize(text))\n",
        "seg_ids = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1, 1]  # 0:前の文章([CLS]から[SEP]まで)の単語、1:後の文章の単語\n",
        "print(seg_ids)\n",
        "show_continuity(text, seg_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjotaOCIeeK"
      },
      "source": [
        "`show_continuity`関数に、自然につながらない2つの文章を与えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "v4qAKBlcGRYb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[9.5296e-06, 9.9999e-01]], grad_fn=<SoftmaxBackward>)\n",
            "0.0009529647286399268%の確率で連続しています。\n"
          ]
        }
      ],
      "source": [
        "text = \"[CLS] What is baseball ? [SEP] This food is made with flour and milk [SEP]\"\n",
        "seg_ids = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # 0:前の文章の単語、1:後の文章の単語\n",
        "show_continuity(text, seg_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getnewargs__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__mod__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__rmod__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'capitalize',\n",
              " 'casefold',\n",
              " 'center',\n",
              " 'count',\n",
              " 'encode',\n",
              " 'endswith',\n",
              " 'expandtabs',\n",
              " 'find',\n",
              " 'format',\n",
              " 'format_map',\n",
              " 'index',\n",
              " 'isalnum',\n",
              " 'isalpha',\n",
              " 'isascii',\n",
              " 'isdecimal',\n",
              " 'isdigit',\n",
              " 'isidentifier',\n",
              " 'islower',\n",
              " 'isnumeric',\n",
              " 'isprintable',\n",
              " 'isspace',\n",
              " 'istitle',\n",
              " 'isupper',\n",
              " 'join',\n",
              " 'ljust',\n",
              " 'lower',\n",
              " 'lstrip',\n",
              " 'maketrans',\n",
              " 'partition',\n",
              " 'removeprefix',\n",
              " 'removesuffix',\n",
              " 'replace',\n",
              " 'rfind',\n",
              " 'rindex',\n",
              " 'rjust',\n",
              " 'rpartition',\n",
              " 'rsplit',\n",
              " 'rstrip',\n",
              " 'split',\n",
              " 'splitlines',\n",
              " 'startswith',\n",
              " 'strip',\n",
              " 'swapcase',\n",
              " 'title',\n",
              " 'translate',\n",
              " 'upper',\n",
              " 'zfill']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(str())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOAgvpyqBM7gw4GACTaXFWY",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03_simple_bert.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "97fc227daf15f558c76cee51fea0c664fdfb6ddf24cf6be9290e749d428101db"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('bert_nlp': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
